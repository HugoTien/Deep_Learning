{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING (theano.configdefaults): g++ not available, if using conda: `conda install m2w64-toolchain`\n",
      "WARNING (theano.configdefaults): g++ not detected ! Theano will be unable to execute optimized C-implementations (for both CPU and GPU) and will default to Python implementations. Performance will be severely degraded. To remove this warning, set Theano flags cxx to an empty string.\n",
      "C:\\Users\\Java\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# !conda install pandas\n",
    "#KERAS\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD,RMSprop,adam\n",
    "from keras.utils import np_utils\n",
    "# from array import array\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import os\n",
    "import theano\n",
    "from PIL import Image\n",
    "from numpy import *\n",
    "# SKLEARN\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Conv3D, MaxPooling3D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Conv3D, MaxPooling3D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "import numpy as np\n",
    "from keras.layers.noise import GaussianDropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11392\n",
      "(11392, 49152)\n",
      "(11392,)\n"
     ]
    }
   ],
   "source": [
    "# input image dimensions\n",
    "img_rows, img_cols = 128, 128\n",
    "# number of channels\n",
    "img_channels = 3\n",
    "\n",
    "# data\n",
    "path1 = 'C:/Users/Java/Desktop/Project/Project_Image/data11/train'    \n",
    "#path of folder of images    \n",
    "path2 = 'C:/Users/Java/Desktop/Project/Project_Image/data11/train_set'  \n",
    "#path of folder to save images    \n",
    "\n",
    "listing = os.listdir(path1) \n",
    "num_samples=size(listing)\n",
    "print(num_samples)\n",
    "\n",
    "for file in listing:\n",
    "    im = Image.open(path1 + '/' + file)   \n",
    "    img = im.resize((img_rows,img_cols))\n",
    "    gray = img.convert('RGBA')\n",
    "                #need to do some more processing here           \n",
    "#     img.save(path2 +'/' +  file, \"JPEG\")\n",
    "    gray.save(path2 +'\\\\' +  file, \"JPEG\")\n",
    "\n",
    "imlist = os.listdir(path2)\n",
    "im1 = array(Image.open(path2 + '/'+ imlist[0])) # open one image to get size\n",
    "m,n = im1.shape[0:2] # get the size of the images\n",
    "imnbr = len(imlist) # get the number of images\n",
    "\n",
    "# create matrix to store all flattened images\n",
    "immatrix = array([array(Image.open(path2+ '/' +im2)).flatten()\n",
    "              for im2 in imlist],'f')\n",
    "                \n",
    "\n",
    "label=np.ones((num_samples,),dtype = int)\n",
    "# np.ones(shape[, dtype, order])\n",
    "# 依据给定形状和类型(shape[, dtype, order])返回一个新的元素全部为1的数组\n",
    "\n",
    "label[0:114]=0  # 二條城\n",
    "label[114:1233]=1  # 三十三間堂\n",
    "label[1233:3789]=2  # 千本鳥居\n",
    "label[3789:5639]=3  # 平等院鳳凰堂 \n",
    "label[5639:5928]=4  # 京都御所\n",
    "label[5928:7857]=5  # 京都塔\n",
    "label[7857:9809]=6  # 金閣寺\n",
    "label[9809:10294]=7  # 清水寺\n",
    "label[10294:11392]=8  # 渡月橋\n",
    "\n",
    "\n",
    "# 0 二條城1-100\t\t1-746\n",
    "# 1 三十三間堂101-200\t747-1796\n",
    "# 2 千本鳥居201-300\t1797-4228\n",
    "# 3 平等院鳳凰堂301-400\t4229-6120\n",
    "# 4 京都御所401-500\t6121-6468\n",
    "# 5 京都塔501-600\t\t6469-7959\n",
    "# 6 金格寺601-700\t\t7960-10028\n",
    "# 7 清水寺701-800\t\t10029-10411\n",
    "# 8 渡月橋801-900\t\t10412-11872\n",
    "\n",
    "data,Label = shuffle(immatrix,label, random_state=3)\n",
    "train_data = [data,Label]\n",
    "\n",
    "img=immatrix[200].reshape(img_rows,img_cols,3)\n",
    "plt.imshow(img)\n",
    "# plt.imshow(img,cmap='gray') \n",
    "# cmap: 颜色图谱（colormap), 默认绘制为RGB(A)颜色空间。\n",
    "print (train_data[0].shape)\n",
    "print (train_data[1].shape)\n",
    "\n",
    "#batch_size to train\n",
    "batch_size = 32\n",
    "# number of output classes\n",
    "nb_classes = 9\n",
    "# number of epochs to train\n",
    "nb_epoch = 30\n",
    "\n",
    "# number of convolutional filters to use\n",
    "nb_filters = 32\n",
    "# size of pooling area for max pooling\n",
    "nb_pool = 2\n",
    "# convolution kernel size\n",
    "nb_conv = 3\n",
    "\n",
    "#%%\n",
    "(X, y) = (train_data[0],train_data[1]) #？？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (9113, 128, 128, 3)\n",
      "9113 train samples\n",
      "2279 test samples\n",
      "label :  [ 0.  0.  0.  0.  0.  0.  0.  0.  1.]\n"
     ]
    }
   ],
   "source": [
    "#batch_size to train\n",
    "batch_size = 100\n",
    "# number of output classes\n",
    "nb_classes = 9\n",
    "# number of epochs to train\n",
    "nb_epoch = 20\n",
    "\n",
    "# number of convolutional filters to use\n",
    "nb_filters = 32\n",
    "# size of pooling area for max pooling\n",
    "nb_pool = 2\n",
    "# convolution kernel size\n",
    "nb_conv = 3\n",
    "\n",
    "#%%\n",
    "(X, y) = (train_data[0],train_data[1]) #？？\n",
    "\n",
    "# STEP 1: split X and y into training and testing sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=4)\n",
    "\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0],img_rows, img_cols,3)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols,3)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "i = 800\n",
    "plt.imshow(X_train[i, 0], interpolation='nearest')\n",
    "print(\"label : \", Y_train[i,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 32)      1568      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128, 128, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 42, 42, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 42, 42, 64)        32832     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 42, 42, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 21, 21, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 21, 21, 128)       131200    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 21, 21, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 10, 10, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 10, 10, 256)       524544    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 10, 10, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "gaussian_dropout_1 (Gaussian (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              6554624   \n",
      "_________________________________________________________________\n",
      "gaussian_dropout_2 (Gaussian (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 9)                 9225      \n",
      "=================================================================\n",
      "Total params: 7,253,993\n",
      "Trainable params: 7,253,993\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Java\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\models.py:844: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9113 samples, validate on 2279 samples\n",
      "Epoch 1/20\n",
      "9113/9113 [==============================] - 299s - loss: 1.5271 - acc: 0.4827 - val_loss: 1.3152 - val_acc: 0.6419\n",
      "Epoch 2/20\n",
      "9113/9113 [==============================] - 294s - loss: 0.9983 - acc: 0.6616 - val_loss: 1.1483 - val_acc: 0.6437\n",
      "Epoch 3/20\n",
      "9113/9113 [==============================] - 294s - loss: 0.8466 - acc: 0.7058 - val_loss: 1.0015 - val_acc: 0.7236\n",
      "Epoch 4/20\n",
      "9113/9113 [==============================] - 296s - loss: 0.7394 - acc: 0.7477 - val_loss: 0.9393 - val_acc: 0.7582\n",
      "Epoch 5/20\n",
      "9113/9113 [==============================] - 295s - loss: 0.6618 - acc: 0.7698 - val_loss: 0.9185 - val_acc: 0.7565\n",
      "Epoch 6/20\n",
      "9113/9113 [==============================] - 295s - loss: 0.6308 - acc: 0.7777 - val_loss: 0.7220 - val_acc: 0.7797\n",
      "Epoch 7/20\n",
      "9113/9113 [==============================] - 294s - loss: 0.6099 - acc: 0.7880 - val_loss: 0.7395 - val_acc: 0.7876\n",
      "Epoch 8/20\n",
      "9113/9113 [==============================] - 294s - loss: 0.5489 - acc: 0.8066 - val_loss: 0.7539 - val_acc: 0.7749\n",
      "Epoch 9/20\n",
      "9113/9113 [==============================] - 300s - loss: 0.5200 - acc: 0.8128 - val_loss: 0.6842 - val_acc: 0.7973\n",
      "Epoch 10/20\n",
      "9113/9113 [==============================] - 295s - loss: 0.4820 - acc: 0.8241 - val_loss: 0.7016 - val_acc: 0.7881\n",
      "Epoch 11/20\n",
      "9113/9113 [==============================] - 298s - loss: 0.4751 - acc: 0.8286 - val_loss: 0.6507 - val_acc: 0.7894\n",
      "Epoch 12/20\n",
      "9113/9113 [==============================] - 301s - loss: 0.4571 - acc: 0.8372 - val_loss: 0.6369 - val_acc: 0.8113\n",
      "Epoch 13/20\n",
      "9113/9113 [==============================] - 294s - loss: 0.4313 - acc: 0.8455 - val_loss: 0.6587 - val_acc: 0.8025\n",
      "Epoch 14/20\n",
      "9113/9113 [==============================] - 294s - loss: 0.4033 - acc: 0.8528 - val_loss: 0.6721 - val_acc: 0.7894\n",
      "Epoch 15/20\n",
      "9113/9113 [==============================] - 295s - loss: 0.4072 - acc: 0.8518 - val_loss: 0.6931 - val_acc: 0.7753\n",
      "Epoch 16/20\n",
      "9113/9113 [==============================] - 295s - loss: 0.4362 - acc: 0.8460 - val_loss: 0.6102 - val_acc: 0.8065\n",
      "Epoch 17/20\n",
      "9113/9113 [==============================] - 295s - loss: 0.3576 - acc: 0.8637 - val_loss: 0.6422 - val_acc: 0.7973\n",
      "Epoch 18/20\n",
      "9113/9113 [==============================] - 295s - loss: 0.3516 - acc: 0.8683 - val_loss: 0.5901 - val_acc: 0.8087\n",
      "Epoch 19/20\n",
      "9113/9113 [==============================] - 295s - loss: 0.3336 - acc: 0.8803 - val_loss: 0.6269 - val_acc: 0.7964\n",
      "Epoch 20/20\n",
      "9113/9113 [==============================] - 295s - loss: 0.3067 - acc: 0.8847 - val_loss: 0.6114 - val_acc: 0.8004\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# 加入卷積層1\n",
    "model.add(Conv2D(filters=32, kernel_size = (4,4),   # 32個3*3濾鏡\n",
    "                 input_shape = (128,128,3),   # 圖片大小&三原色\n",
    "                 activation = 'relu',\n",
    "                 padding = 'same' # 經過此層影像大小不變\n",
    "                 ) \n",
    "         )\n",
    "\n",
    "\n",
    "# 控制overfit\n",
    "model.add(Dropout(rate=0.25))    \n",
    "\n",
    "\n",
    "# 加入池化層1\n",
    "model.add(MaxPooling2D(pool_size=(3,3))) \n",
    "\n",
    "##################################################################\n",
    "\n",
    "# 加入卷積層2\n",
    "model.add(Conv2D(filters=64, kernel_size = (4,4),   # 64個3*3濾鏡\n",
    "                 activation = 'relu',\n",
    "                 padding = 'same' # 經過此層影像大小不變\n",
    "                 ) \n",
    "         )\n",
    "\n",
    "\n",
    "# 控制overfit\n",
    "model.add(Dropout(rate=0.25))          \n",
    "\n",
    "\n",
    "\n",
    "# 加入池化層2\n",
    "model.add(MaxPooling2D(pool_size=(2,2))) \n",
    "\n",
    "##################################################################\n",
    "\n",
    "# 加入卷積層3\n",
    "model.add(Conv2D(filters=128, kernel_size = (4,4),   # 64個3*3濾鏡\n",
    "                 activation = 'relu',\n",
    "                 padding = 'same' # 經過此層影像大小不變\n",
    "                 ) \n",
    "         )\n",
    "\n",
    "\n",
    "# 控制overfit\n",
    "model.add(Dropout(rate=0.25))          \n",
    "\n",
    "\n",
    "\n",
    "# 加入池化層4\n",
    "model.add(MaxPooling2D(pool_size=(2,2))) \n",
    "\n",
    "##################################################################\n",
    "\n",
    "# 加入卷積層2\n",
    "model.add(Conv2D(filters=256, kernel_size = (4,4),   # 64個3*3濾鏡\n",
    "                 activation = 'relu',\n",
    "                 padding = 'same' # 經過此層影像大小不變\n",
    "                 ) \n",
    "         )\n",
    "\n",
    "\n",
    "# 控制overfit\n",
    "model.add(Dropout(rate=0.25))          \n",
    "\n",
    "\n",
    "\n",
    "# 加入池化層2\n",
    "model.add(MaxPooling2D(pool_size=(2,2))) \n",
    "\n",
    "##################################################################\n",
    "\n",
    "# 加入平坦層\n",
    "model.add(Flatten())\n",
    "\n",
    "\n",
    "# 控制overfit\n",
    "model.add(GaussianDropout(rate=0.25))      \n",
    "\n",
    "\n",
    "##################################################################\n",
    "\n",
    "# 加入隱藏層\n",
    "model.add(Dense(1024, activation = 'relu'))\n",
    "\n",
    "\n",
    "# 控制overfit\n",
    "model.add(GaussianDropout(rate=0.25))    \n",
    "\n",
    "# 控制overfit\n",
    "model.add(Dropout(rate=0.25))    \n",
    "\n",
    "##################################################################\n",
    "##################################################################\n",
    "# 建立輸出層\n",
    "model.add(Dense(9, activation = 'softmax'))\n",
    "\n",
    "##################################################################\n",
    "\n",
    "# 查看模型摘要\n",
    "print(model.summary())\n",
    "\n",
    "##################################################################\n",
    "\n",
    "###############################\n",
    "#                             #\n",
    "#          準備訓練            #\n",
    "#                             #\n",
    "###############################\n",
    "model.compile(loss = 'categorical_crossentropy',  # 損失函數\n",
    "              optimizer = 'Adam',                 # 最優化方法\n",
    "              metrics = ['accuracy'])             # 以準確率評估\n",
    "\n",
    "#%%\n",
    "\n",
    "hist = model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "              verbose=1, validation_data=(X_test, Y_test))\n",
    "            \n",
    "            \n",
    "# hist = model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "#               verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-e936c4bf1e7f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'validation'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'upper left'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 設定圖例是顯示'train', 'validation'，位置在左上角\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mshow_train_history\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'val_acc'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0mshow_train_history\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'hist' is not defined"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "def show_train_history(train_history,train,validation):   # train:訓練資料執行結果 \n",
    "    plt.plot(hist.history[train])  # train_history:之前訓練過程產生的資料\n",
    "    plt.plot(train_history.history[validation])  # validation:驗證資料的執行結果\n",
    "    plt.title('Train History') # 顯示圖形的標題\n",
    "    plt.ylabel(train) # 顯示y軸的標題\n",
    "    plt.xlabel('Epoch') # 設定x軸標籤是'Epoch'\n",
    "    plt.legend(['train', 'validation'], loc='upper left') # 設定圖例是顯示'train', 'validation'，位置在左上角\n",
    "    plt.show()\n",
    "show_train_history(hist,'acc','val_acc')\n",
    "show_train_history(hist,'loss','val_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2279/2279 [==============================] - 17s    \n",
      "[5 8 5 ..., 6 2 5]\n",
      "2279/2279 [==============================] - 17s    \n",
      "[[  0  17   1   1   0   3   2   0   0]\n",
      " [  7 179   3   2   1  14   6   0   0]\n",
      " [  1   7 399  68   0  20  12   0   1]\n",
      " [  0   0   0 387   5   0   5   0   0]\n",
      " [  0   0   0  46   4   0   3   0   0]\n",
      " [  0   4   1  24   0 342   3   0   0]\n",
      " [  1   1   2   8   0  20 322  16  39]\n",
      " [  0   2   0   4   0   1  22  18  54]\n",
      " [  0   2   1   0   0   0  18   7 173]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "y_pred = model.predict_classes(X_test)\n",
    "print(y_pred)\n",
    "\n",
    "p=model.predict_proba(X_test) # to predict probability\n",
    "\n",
    "target_names = ['class 0(二條城)', 'class 1(三十三間堂)', 'class 2(千本鳥居)','class 3(平等院鳳凰堂)','class 4(京都御所)','class 5(京都塔)','class 6(金閣寺)','class 7(清水寺)','class 8(渡月橋)']\n",
    "# print(classification_report(np.argmax(Y_test,axis=1), y_pred,target_names=target_names))\n",
    "print(confusion_matrix(np.argmax(Y_test,axis=1), y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 6, 2, ..., 7, 2, 5])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
